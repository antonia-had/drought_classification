{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c99d8be",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Investigate the impacts of all realizations on all users "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e81ac638",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import duckdb\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5518cfe2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load drought counts and classify each realization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load in all drought counts for all realizations\n",
    "droughts_df = pd.read_csv('../rival_framings_demand/drought_counts_all_realizations_non_stationary.csv', index_col=0)\n",
    "droughts_df.index = np.arange(1, len(droughts_df) + 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# We will use these counts to classify whether a realization belongs \n",
    "# in history, paleo variability, or all-encompassing experiments\n",
    "\n",
    "# create a list of our conditions\n",
    "conditions = [\n",
    "    (droughts_df['Decadal counts']/105*100 <= 21) & (droughts_df['Multidecadal counts']/105*100 == 0), #history criteria\n",
    "    ((droughts_df['Decadal counts']/105*100 > 21) | (droughts_df['Multidecadal counts']/105*100 > 0)) & #paleo criteria\n",
    "    (droughts_df['Decadal counts']/105*100 <= 57) & (droughts_df['Multidecadal counts']/105*100 <= 42),\n",
    "    (droughts_df['Decadal counts']/105*100 > 57) | (droughts_df['Multidecadal counts']/105*100 > 42)] #all-encompassing critera\n",
    "\n",
    "# create a list of the values we want to assign for each condition\n",
    "values = ['History', 'Paleo', 'Encompassing']\n",
    "\n",
    "# create a new column and use np.select to assign values to it using our lists as arguments\n",
    "droughts_df['Classification'] = np.select(conditions, values)\n",
    "\n",
    "# display updated DataFrame\n",
    "droughts_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "droughts_df['Classification'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# directory where the experiment data is stored\n",
    "flow_data_dir = '../rival_framings_demand/xdd_parquet_flow'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loop through every realization and calculate summary impact metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Function converting order number to sample and realization for file retrieval"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "no_to_realization = lambda x: (int((x-1)/10)+1, (x-1)%10+1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create empty dataframe to store impacts summary per realization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dtypes = np.dtype(\n",
    "    [\n",
    "        (\"Duration\", int),\n",
    "        (\"Magnitude\", float),\n",
    "        (\"%_users\", float),\n",
    "        (\"Outflow_drought_min\", float),\n",
    "        (\"Outflow_10th\", float)\n",
    "    ]\n",
    ")\n",
    "df_impacts = pd.DataFrame(np.zeros(1000, dtype=dtypes))\n",
    "df_impacts.index = np.arange(1, len(df_impacts) + 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define function to calculate duration of continuous occurences"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def shortage_duration(sequence, threshold):\n",
    "    cnt_shrt = [sequence[i]>=threshold for i in range(len(sequence))] # Returns a list of True values when there's a shortage\n",
    "    shrt_dur = [ sum( 1 for _ in group ) for key, group in itertools.groupby( cnt_shrt ) if key ] # Counts groups of True values\n",
    "    return shrt_dur"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Historic rolling sum deliveries (calculated in annual_outflow.txt)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "deliveries_thresholds = [35000, 43220, 44896] #Hypothetical, Hist. Min, Hist. 5th"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define function that identifies the percentile violated"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def percentile(x):\n",
    "    for i, per in enumerate(deliveries_thresholds):\n",
    "        if x<= per:\n",
    "            violation = i\n",
    "            break\n",
    "        else:\n",
    "            violation = 999\n",
    "    return violation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loop through all realizations and calculate user impacts and effects on basin outflows"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "WDs = [36, 37, 38, 39, 45, 50, 51, 52, 53, 70, 72]\n",
    "\n",
    "for k in df_impacts.index:\n",
    "    print(k)\n",
    "    \n",
    "    realization_index = k\n",
    "    # get sample and realization for file retrieval\n",
    "    sample, real = no_to_realization(realization_index)\n",
    "    # get years that are in drought in specific realization\n",
    "    years = list(itertools.chain.from_iterable(ast.literal_eval(droughts_df.at[int(realization_index),'Drought years'])))\n",
    "    years = tuple([x+1908 for x in years])\n",
    "    \n",
    "    # only do the following if there's at least one drought year\n",
    "    # if there is no drought, values will stay default (zero) and we only need to calculate outflow percentile\n",
    "    \n",
    "    # target glob path\n",
    "    glob_path = os.path.join(flow_data_dir, f'S{sample}_{real}.parquet')\n",
    "    \n",
    "    sql = f\"\"\"\n",
    "    SELECT\n",
    "        SUM(river_outflow)*1233.4818/1000000 AS annual_river_outflow\n",
    "    FROM\n",
    "        '{glob_path}'\n",
    "    GROUP BY\n",
    "        structure_id\n",
    "        ,year\n",
    "    HAVING\n",
    "        structure_id = '09163500'\n",
    "    ORDER BY\n",
    "        year;\n",
    "    \"\"\"     \n",
    "    # get query result as a data frame\n",
    "    try:\n",
    "        df_flows = duckdb.query(sql).df()\n",
    "        df_impacts.at[realization_index, \"Outflow_10th\"] = np.nanpercentile(df_flows['annual_river_outflow'].rolling(10).sum(), 10)\n",
    "    except RuntimeError:\n",
    "        print(f'missing file S{sample}_{real}')\n",
    "    if years:\n",
    "        sql = f\"\"\"\n",
    "        SELECT\n",
    "            SUM(river_outflow)*1233.4818/1000000 AS annual_river_outflow\n",
    "        FROM\n",
    "            '{glob_path}'\n",
    "        GROUP BY\n",
    "            structure_id\n",
    "            ,year\n",
    "        HAVING\n",
    "            year in {years} AND structure_id = '09163500'\n",
    "        ORDER BY\n",
    "            year;\n",
    "        \"\"\"        \n",
    "        try:\n",
    "            # get query result as a data frame\n",
    "            df_flows_drought = duckdb.query(sql).df()\n",
    "\n",
    "            #filter out gauge structures and keep only drought years\n",
    "            # Calculate shortage to drought percentage\n",
    "            sql = f\"\"\"\n",
    "            SELECT \n",
    "                structure_id\n",
    "                ,year\n",
    "                ,shortage\n",
    "                ,demand\n",
    "                ,shortage/demand*100 as ratio\n",
    "            FROM\n",
    "                '{glob_path}'\n",
    "            WHERE\n",
    "                year in {years}\n",
    "                AND structure_id NOT LIKE '09%' ; \n",
    "            \"\"\"\n",
    "            df = duckdb.query(sql).df()\n",
    "\n",
    "            df['ratio'] = df['ratio'].fillna(0)\n",
    "\n",
    "            # Get list of users\n",
    "            users = df['structure_id'].unique()\n",
    "            \n",
    "            # Create dataframe to store impacts for each user (no of users = 343)\n",
    "            dtypes = np.dtype(\n",
    "                [\n",
    "                    (\"Duration\", int),\n",
    "                    (\"Magnitude\", float),\n",
    "                    (\"Experienced_shortage\", int)\n",
    "                ]\n",
    "            )\n",
    "            user_impacts_summary = pd.DataFrame(np.zeros(343, dtype=dtypes))\n",
    "            user_impacts_summary.index = users\n",
    "\n",
    "            # Loop through all users and calculate individual impacts\n",
    "            for index, row in user_impacts_summary.iterrows():\n",
    "                user_impacts = df[df['structure_id']==index]\n",
    "                if np.sum(user_impacts['ratio']) > 0: # check if user experienced any impacts\n",
    "                    user_impacts_summary.at[index, \"Experienced_shortage\"] = 1\n",
    "                    # calculate mean user impacts\n",
    "                    user_impacts_summary.at[index, \"Magnitude\"] = np.around(np.mean(user_impacts['ratio']), \n",
    "                                                                            decimals= 1) \n",
    "                    # calculate longest duration of at least mean\n",
    "                    user_shrt_dur = shortage_duration(user_impacts['ratio'].values, \n",
    "                                                      user_impacts_summary.at[index, \"Magnitude\"]) \n",
    "                    if user_shrt_dur:\n",
    "                        user_impacts_summary.at[index, \"Duration\"] = np.around(np.max(user_shrt_dur)/12, \n",
    "                                                                               decimals= 1) \n",
    "                        \n",
    "            # Summarize impacts across all users \n",
    "            df_impacts.at[realization_index, \"%_users\"] = np.around(np.mean(user_impacts_summary[\"Experienced_shortage\"])*100, \n",
    "                                                                    decimals= 0)\n",
    "            df_impacts.at[realization_index, \"Magnitude\"] = np.around(np.mean(user_impacts_summary[\"Magnitude\"]), \n",
    "                                                                      decimals= 0)\n",
    "            df_impacts.at[realization_index, \"Duration\"] = np.around(np.mean(user_impacts_summary[\"Duration\"]), \n",
    "                                                                     decimals= 0)\n",
    "            df_impacts.at[realization_index, \"Outflow_drought_min\"] = np.min(df_flows_drought['annual_river_outflow'].rolling(10).sum())\n",
    "            \n",
    "            # Summarize impacts across WDs\n",
    "            for wd in WDs:\n",
    "                df_impacts.at[realization_index, f\"%_users_{wd}\"] = np.around(np.mean(user_impacts_summary[\"Experienced_shortage\"].filter(regex=f'^{wd}', \n",
    "                                                                                                                                         axis=0))*100, \n",
    "                                                                              decimals= 0)\n",
    "                df_impacts.at[realization_index, f\"Magnitude_{wd}\"] = np.around(np.mean(user_impacts_summary[\"Magnitude\"].filter(regex=f'^{wd}', \n",
    "                                                                                                                                 axis=0)), \n",
    "                                                                                decimals= 0)\n",
    "        except RuntimeError:\n",
    "            print(f'missing file S{sample}_{real}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_impacts['Classification'] = droughts_df['Classification']\n",
    "df_impacts.to_csv('drought_impacts_all_realizations.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_impacts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_impacts['Classification'] = droughts_df['Classification']\n",
    "df_impacts.to_csv('drought_impacts_all_realizations_non_stationary.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c608274",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_impacts['Classification'] = droughts_df['Classification']\n",
    "df_impacts.to_csv('drought_impacts_all_realizations_non_stationary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e96a8dc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}